{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging face is an open source ML hub. They have models, datasets and spaces that allows users to use their models, datasets and spaces to build and deploy their LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers are libraries that makes downloading and training ML models easy.\n",
    "For example, to implement sentimental analysis with pipeline():\n",
    "pipeline(task=\"sentimental-analysis\")(\"Love this\")\n",
    "\n",
    "- You can specify the model and fine tune them according to your task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anish\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anish\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 759/759 [00:00<00:00, 759kB/s]\n",
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\anish\\.cache\\huggingface\\hub\\models--lxyuan--distilbert-base-multilingual-cased-sentiments-student. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 541M/541M [02:12<00:00, 4.07MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 373/373 [00:00<?, ?B/s] \n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 3.04MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.92M/2.92M [00:00<00:00, 3.36MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task = \"sentiment-analysis\",model = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.8623678088188171}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Hate this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9899442195892334},\n",
       " {'label': 'neutral', 'score': 0.7590078711509705},\n",
       " {'label': 'positive', 'score': 0.6209117770195007},\n",
       " {'label': 'positive', 'score': 0.8014581799507141}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also pass the list to a classifier\n",
    "text_list = [\"This is great\",\"This is nothing\",\"You've got to work on your face\",\"You're beautiful, never change\"]\n",
    "classifier(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task = \"text-classification\",model = \"SamLowe/roberta-base-go_emotions\",top_k = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'admiration', 'score': 0.9526104927062988},\n",
       "  {'label': 'approval', 'score': 0.030472073704004288},\n",
       "  {'label': 'neutral', 'score': 0.015236238949000835},\n",
       "  {'label': 'excitement', 'score': 0.006063767243176699},\n",
       "  {'label': 'gratitude', 'score': 0.005296194460242987},\n",
       "  {'label': 'joy', 'score': 0.004475215449929237},\n",
       "  {'label': 'curiosity', 'score': 0.004322331864386797},\n",
       "  {'label': 'realization', 'score': 0.004089603666216135},\n",
       "  {'label': 'optimism', 'score': 0.00407722033560276},\n",
       "  {'label': 'disapproval', 'score': 0.004076561890542507},\n",
       "  {'label': 'annoyance', 'score': 0.0035287425853312016},\n",
       "  {'label': 'surprise', 'score': 0.0029730682726949453},\n",
       "  {'label': 'disappointment', 'score': 0.002734640846028924},\n",
       "  {'label': 'love', 'score': 0.00269458070397377},\n",
       "  {'label': 'amusement', 'score': 0.0024867462925612926},\n",
       "  {'label': 'confusion', 'score': 0.0023607409093528986},\n",
       "  {'label': 'pride', 'score': 0.0021013382356613874},\n",
       "  {'label': 'sadness', 'score': 0.001773053896613419},\n",
       "  {'label': 'anger', 'score': 0.0017196929547935724},\n",
       "  {'label': 'caring', 'score': 0.0013670080807060003},\n",
       "  {'label': 'desire', 'score': 0.001047872588969767},\n",
       "  {'label': 'disgust', 'score': 0.0009689946309663355},\n",
       "  {'label': 'fear', 'score': 0.0005249780369922519},\n",
       "  {'label': 'relief', 'score': 0.0004862115893047303},\n",
       "  {'label': 'embarrassment', 'score': 0.00034175056498497725},\n",
       "  {'label': 'grief', 'score': 0.00033891951898112893},\n",
       "  {'label': 'remorse', 'score': 0.0002780948707368225},\n",
       "  {'label': 'nervousness', 'score': 0.00020788486290257424}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(text_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.58k/1.58k [00:00<?, ?B/s]\n",
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\anish\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 1.63G/1.63G [04:23<00:00, 6.16MB/s]\n",
      "generation_config.json: 100%|██████████| 363/363 [00:00<00:00, 362kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 6.30MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 6.08MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 5.83MB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\",model = \"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Emory Andrew Tate III (born 1 December 1986), also known as Cobra Tate, King Cobra and Top G is a British American social media personality, businessman, and 4 time kickboxing world champion who also fought in K-1. In 2016 he appeared on the British reality show Big Brother but was removed as he was the suspect in an open rape investigation in the UK. After his kickboxing career, Tate and his brother, Tristan, began operating a webcam model business, followed by selling online courses; notably Hustler's University, which gained 100,000 subscribers, later rebranded to The Real World, and the secretive War Room group, which has been accused by the BBC of grooming women into sex work and teaching violence against women.[3]\n",
    "\n",
    "His controversial commentary has resulted in de-platforming from various social media platforms[4] and concern from advocacy groups, charities, non-profit organisations, teachers, parents, mental health experts, as well as UK counter-terror police. Surveys have found that most Britons have heard of Tate, who is viewed favourably among many young men, considered influential, and has been dubbed the \"king of toxic masculinity\" by multiple media outlets,[5] as part of the \"manosphere\".[6] With appearances on conspiracy news site InfoWars, Tate has been described as a right-wing and far-right influencer, and has described himself as \"absolutely\" misogynistic and sexist. In August 2023, it was estimated that Tate's online ventures generated US$5 million in revenue per month. As of December 2023, Tate had over 8.5 million followers on X (formerly Twitter) and was the third-most \"googled\" person in 2023.\n",
    "\n",
    "\"\"\"\n",
    "summarized_text = summarizer(text,min_length = 5, max_length = 140)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emory Andrew Tate III (born 1 December 1986), also known as Cobra Tate, King Cobra and Top G is a British American social media personality, businessman, and 4 time kickboxing world champion. In 2016 he appeared on the British reality show Big Brother but was removed as he was the suspect in an open rape investigation in the UK. After his kickboxing career, Tate and his brother, Tristan, began operating a webcam model business, followed by selling online courses.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'neutral', 'score': 0.8198052644729614},\n",
       "  {'label': 'realization', 'score': 0.06418311595916748},\n",
       "  {'label': 'sadness', 'score': 0.059627220034599304},\n",
       "  {'label': 'approval', 'score': 0.05475388094782829},\n",
       "  {'label': 'disappointment', 'score': 0.03001587465405464},\n",
       "  {'label': 'annoyance', 'score': 0.00990300439298153},\n",
       "  {'label': 'disapproval', 'score': 0.007488118018954992},\n",
       "  {'label': 'admiration', 'score': 0.006592709105461836},\n",
       "  {'label': 'embarrassment', 'score': 0.006175072398036718},\n",
       "  {'label': 'disgust', 'score': 0.005816112272441387},\n",
       "  {'label': 'fear', 'score': 0.005254390649497509},\n",
       "  {'label': 'grief', 'score': 0.0035114712081849575},\n",
       "  {'label': 'love', 'score': 0.002852250821888447},\n",
       "  {'label': 'joy', 'score': 0.0027828377205878496},\n",
       "  {'label': 'remorse', 'score': 0.002685344312340021},\n",
       "  {'label': 'optimism', 'score': 0.0025211411993950605},\n",
       "  {'label': 'relief', 'score': 0.0024682963266968727},\n",
       "  {'label': 'anger', 'score': 0.0024250629357993603},\n",
       "  {'label': 'nervousness', 'score': 0.0018716859631240368},\n",
       "  {'label': 'desire', 'score': 0.0018591434927657247},\n",
       "  {'label': 'amusement', 'score': 0.0018547393847256899},\n",
       "  {'label': 'caring', 'score': 0.0017574598314240575},\n",
       "  {'label': 'confusion', 'score': 0.0016420604661107063},\n",
       "  {'label': 'pride', 'score': 0.0014686539070680737},\n",
       "  {'label': 'surprise', 'score': 0.001227930304594338},\n",
       "  {'label': 'excitement', 'score': 0.0010627943556755781},\n",
       "  {'label': 'gratitude', 'score': 0.0008624076726846397},\n",
       "  {'label': 'curiosity', 'score': 0.0007020609918981791}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using two tasks together\n",
    "classifier(summarized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.57k/1.57k [00:00<00:00, 1.57MB/s]\n",
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\anish\\.cache\\huggingface\\hub\\models--facebook--blenderbot-400M-distill. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "pytorch_model.bin: 100%|██████████| 730M/730M [01:41<00:00, 7.21MB/s] \n",
      "generation_config.json: 100%|██████████| 347/347 [00:00<00:00, 349kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 1.15k/1.15k [00:00<?, ?B/s]\n",
      "vocab.json: 100%|██████████| 127k/127k [00:00<00:00, 2.23MB/s]\n",
      "merges.txt: 100%|██████████| 62.9k/62.9k [00:00<00:00, 10.5MB/s]\n",
      "added_tokens.json: 100%|██████████| 16.0/16.0 [00:00<00:00, 16.0kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 772/772 [00:00<?, ?B/s] \n",
      "tokenizer.json: 100%|██████████| 310k/310k [00:00<00:00, 6.30MB/s]\n"
     ]
    }
   ],
   "source": [
    "chatbot = pipeline(model = \"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: c4181af7-2561-490a-a3b8-c47d84a241a3\n",
       "user: Hi I'm Anish, how are you?\n",
       "assistant:  Hi Anish! I'm doing well. How are you doing this fine evening? "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Conversation\n",
    "conversation = Conversation(\"Hi I'm Anish, how are you?\")\n",
    "conversation = chatbot(conversation)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_user_input(\"Where do you work?\")\n",
    "conversation = chatbot(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: c4181af7-2561-490a-a3b8-c47d84a241a3\n",
       "user: Hi I'm Anish, how are you?\n",
       "assistant:  Hi Anish! I'm doing well. How are you doing this fine evening? \n",
       "user: Where do you work?\n",
       "assistant:  I work at a grocery store. What about you? What do you do for a living?"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1177, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 662, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py\", line 460, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_11776\\3845784893.py\", line 6, in vanilla_chatbot\n",
      "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
      "                                                                                                     ^^^^^^^^^^^^^\n",
      "NameError: name 'response_list' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1177, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 662, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py\", line 460, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_11776\\3845784893.py\", line 6, in vanilla_chatbot\n",
      "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
      "                                                                                                     ^^^^^^^^^^^^^\n",
      "NameError: name 'response_list' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1177, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 662, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py\", line 460, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_11776\\3845784893.py\", line 6, in vanilla_chatbot\n",
      "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
      "                                                                                                     ^^^^^^^^^^^^^\n",
      "NameError: name 'response_list' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1177, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 662, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py\", line 460, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_11776\\3845784893.py\", line 6, in vanilla_chatbot\n",
      "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
      "                                                                                                     ^^^^^^^^^^^^^\n",
      "NameError: name 'response_list' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1177, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 662, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py\", line 460, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_11776\\3845784893.py\", line 6, in vanilla_chatbot\n",
      "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
      "                                                                                                     ^^^^^^^^^^^^^\n",
      "NameError: name 'response_list' is not defined\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "message_list = []\n",
    "reponse_list = []\n",
    "\n",
    "def vanilla_chatbot(message, history):\n",
    "    conversation = Conversation(text = message, past_user_inputs = message_list,generated_response = response_list)\n",
    "    conversation = chatbot(conversation)\n",
    "\n",
    "    return conversation.generated_response[-1]\n",
    "\n",
    "demo_chatbot = gr.ChatInterface(vanilla_chatbot,title = \"Vanilla Chatbot\", description = \"Enter text to start chatting\")\n",
    "demo_chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
