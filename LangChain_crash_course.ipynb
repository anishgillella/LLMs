{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain is a framework that allows you to build applications on top of LLMs.\n",
    "The limitations we have when building an application over OpenAI API are:\n",
    "- Higher cost\n",
    "- No access to internet or real time data\n",
    "- No access to personal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-***************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"La Dolce Vita\" \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature = 0.6)\n",
    "name = llm(\"I want to open an restaurant for Italian food. Suggest a fancy name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open an restaurant for Mexican food. Suggest a fancy name for this.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine = \"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\"Telugu Spice Palace\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm,prompt = prompt_template_name)\n",
    "chain.run(\"Telugu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Sequential Chain :  The process where the out put of a prompt is input of another prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables= ['restaurant_name'],\n",
    "    template = \"\"\"Suggest some menu items for {restaurant_name}. Return it as comma separated list\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Appetizers: \n",
      "- Guacamole and chips \n",
      "- Queso dip \n",
      "- Tostadas \n",
      "- Ceviche \n",
      "- Empanadas \n",
      "\n",
      "2. Main dishes: \n",
      "- Carne asada \n",
      "- Pollo en mole \n",
      "- Tamales \n",
      "- Enchiladas \n",
      "- Fajitas \n",
      "\n",
      "3. Sides: \n",
      "- Arroz con frijoles \n",
      "- Elote (Mexican street corn) \n",
      "- Papas fritas \n",
      "- Platanos maduros \n",
      "- Chile rellenos \n",
      "\n",
      "4. Salads: \n",
      "- Ensalada de nopales (cactus salad) \n",
      "- Ensalada de aguacate (avocado salad) \n",
      "- Ensalada de frutas (fruit salad) \n",
      "\n",
      "5. Desserts: \n",
      "- Tres leches cake \n",
      "- Churros \n",
      "- Flan \n",
      "- Bu√±uelos \n",
      "- Pastel de chocolate \n",
      "\n",
      "6. Beverages: \n",
      "- Margaritas \n",
      "- Horchata \n",
      "- Agua fresca \n",
      "- Cervezas \n",
      "- Refrescos (sodas)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [name_chain,food_items_chain])\n",
    "response = chain.run(\"Mexican\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Sequential Chain have a single input and output but Sequential Chains have mutliple inputs and multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open an restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt=prompt_template_name,output_key='restaurant_name')\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables= ['restaurant_name'],\n",
    "    template = \"\"\"Suggest some menu items for {restaurant_name}. Return it as comma separated list\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt=prompt_template_items,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Al-Amirah Cuisine\"',\n",
       " 'menu_items': '\\n\\n1. Hummus with Pita Bread\\n2. Falafel Platter\\n3. Shawarma Wrap\\n4. Baba Ghanoush\\n5. Tabouli Salad\\n6. Lamb Kebabs\\n7. Chicken Shawarma Plate\\n8. Stuffed Grape Leaves\\n9. Mediterranean Grilled Fish\\n10. Baklava for dessert'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains=[name_chain,food_items_chain],\n",
    "                input_variables=[\"cuisine\"],\n",
    "                output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    "                )\n",
    "\n",
    "chain({'cuisine':'Arabic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__ror__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '__weakref__',\n",
       " '_abatch_with_config',\n",
       " '_abc_impl',\n",
       " '_acall',\n",
       " '_acall_with_config',\n",
       " '_atransform_stream_with_config',\n",
       " '_batch_with_config',\n",
       " '_calculate_keys',\n",
       " '_call',\n",
       " '_call_with_config',\n",
       " '_chain_type',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_is_protocol',\n",
       " '_iter',\n",
       " '_lc_kwargs',\n",
       " '_run_output_key',\n",
       " '_transform_stream_with_config',\n",
       " '_validate_inputs',\n",
       " '_validate_outputs',\n",
       " 'abatch',\n",
       " 'acall',\n",
       " 'ainvoke',\n",
       " 'apply',\n",
       " 'arun',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'bind',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'chains',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'input_keys',\n",
       " 'input_schema',\n",
       " 'input_variables',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'memory',\n",
       " 'metadata',\n",
       " 'name',\n",
       " 'output_keys',\n",
       " 'output_schema',\n",
       " 'output_variables',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'prep_inputs',\n",
       " 'prep_outputs',\n",
       " 'raise_callback_manager_deprecation',\n",
       " 'return_all',\n",
       " 'run',\n",
       " 'save',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set_verbose',\n",
       " 'stream',\n",
       " 'tags',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'transform',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_chains',\n",
       " 'verbose',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
